import { NextRequest, NextResponse } from 'next/server';
import { promises as fs } from 'fs';
import path from 'path';
import { SpiderConfig } from '../../types';

export async function POST(request: NextRequest) {
  try {
    const { config }: { config: SpiderConfig } = await request.json();

    if (!config) {
      return NextResponse.json(
        { error: 'é…ç½®æ•°æ®ä¸èƒ½ä¸ºç©º' },
        { status: 400 }
      );
    }

    // ç”ŸæˆPythonçˆ¬è™«é…ç½®æ–‡ä»¶
    const spiderCode = generateSpiderCode(config);
    
    // ä¿å­˜åˆ°pachongç›®å½•
    const spiderDir = path.join(process.cwd(), '..', 'pachong');
    const configSpiderPath = path.join(spiderDir, `spider_${config.productId}_${Date.now()}.py`);
    
    await fs.writeFile(configSpiderPath, spiderCode, 'utf-8');

    // åŒæ—¶æ›´æ–°åŸå§‹çˆ¬è™«æ–‡ä»¶
    const originalSpiderPath = path.join(spiderDir, 'spider.py');
    const updatedOriginalCode = await updateOriginalSpider(originalSpiderPath, config);
    await fs.writeFile(originalSpiderPath, updatedOriginalCode, 'utf-8');

    return NextResponse.json({
      success: true,
      message: 'é…ç½®å·²å¯¼å‡ºåˆ°çˆ¬è™«ç³»ç»Ÿ',
      files: [
        configSpiderPath,
        originalSpiderPath
      ]
    });
  } catch (error) {
    console.error('å¯¼å‡ºé…ç½®å¤±è´¥:', error);
    return NextResponse.json(
      { error: 'å¯¼å‡ºé…ç½®å¤±è´¥' },
      { status: 500 }
    );
  }
}

function generateSpiderCode(config: SpiderConfig): string {
  const headersStr = JSON.stringify(config.headers, null, 8);
  const cookiesStr = JSON.stringify(config.cookies);

  return `#!/usr/bin/env python3
"""
è‡ªåŠ¨ç”Ÿæˆçš„æ·˜å®/å¤©çŒ«å•†å“è¯„è®ºçˆ¬è™«
å•†å“ID: ${config.productId}
ç”Ÿæˆæ—¶é—´: ${new Date().toLocaleString()}
"""

import requests
import time
import json
import urllib.parse
import re
import hashlib
import os
from fake_useragent import UserAgent


class TmallCommentSpider:
    """å¤©çŒ«å•†å“è¯„è®ºçˆ¬è™« - è‡ªåŠ¨é…ç½®ç‰ˆæœ¬"""
    
    def __init__(self):
        self.session = requests.Session()
        self.ua = UserAgent()
        self.base_url = "${config.baseUrl}"
        self.product_id = "${config.productId}"
        
        # è‡ªåŠ¨é…ç½®çš„è¯·æ±‚å¤´
        self.headers = ${headersStr}
        
        # è‡ªåŠ¨é…ç½®çš„cookies
        self.cookies_str = ${cookiesStr}
        
        if self.cookies_str:
            self.session.cookies.update(self._parse_cookies(self.cookies_str))
    
    def _parse_cookies(self, cookie_string):
        """è§£æcookieå­—ç¬¦ä¸²ä¸ºå­—å…¸"""
        cookies = {}
        if cookie_string:
            for item in cookie_string.split('; '):
                if '=' in item:
                    key, value = item.split('=', 1)
                    cookies[key] = value
        return cookies
    
    def _extract_token(self, cookies_str):
        """ä»cookiesä¸­æå–_m_h5_tk token"""
        match = re.search(r'_m_h5_tk=([^;]+)', cookies_str)
        if match:
            token_with_timestamp = match.group(1)
            token = token_with_timestamp.split('_')[0] if '_' in token_with_timestamp else token_with_timestamp
            return token
        return ""
    
    def _generate_signature(self, timestamp, data_str, token=""):
        """ç”Ÿæˆç­¾å"""
        app_key = "12574478"
        if not token:
            sign_str = f"{timestamp}&{app_key}&{data_str}"
        else:
            sign_str = f"{token}&{timestamp}&{app_key}&{data_str}"
        return hashlib.md5(sign_str.encode('utf-8')).hexdigest()
    
    def _parse_jsonp_response(self, response_text):
        """è§£æJSONPå“åº”"""
        match = re.search(r'mtopjsonp\\d+\\((.*)\\)', response_text)
        if match:
            json_str = match.group(1)
            try:
                return json.loads(json_str)
            except json.JSONDecodeError as e:
                print(f"JSONè§£æé”™è¯¯: {e}")
                return None
        return None
    
    def _format_comments(self, raw_data):
        """æ ¼å¼åŒ–è¯„è®ºæ•°æ®"""
        if not raw_data or 'data' not in raw_data:
            return []
        
        comments = []
        try:
            rate_list = raw_data['data'].get('rateList', [])
            
            for rate in rate_list:
                comment = {
                    'user_nick': rate.get('userNick', rate.get('reduceUserNick', '')),
                    'content': rate.get('feedback', ''),
                    'rating': int(rate.get('userStar', 0)),
                    'date': rate.get('feedbackDate', rate.get('createTime', '')),
                    'useful_count': 0,
                    'reply': rate.get('reply', ''),
                    'sku_info': rate.get('skuValueStr', ''),
                    'pics': []
                }
                
                if 'interactInfo' in rate and isinstance(rate['interactInfo'], dict):
                    comment['useful_count'] = int(rate['interactInfo'].get('likeCount', 0))
                
                if 'feedPicPathList' in rate and isinstance(rate['feedPicPathList'], list):
                    comment['pics'] = rate['feedPicPathList']
                
                comments.append(comment)
                
        except Exception as e:
            print(f"æ•°æ®æ ¼å¼åŒ–é”™è¯¯: {e}")
        
        return comments
    
    def get_comments(self, page_no=1, page_size=${config.pageSize}):
        """è·å–å•†å“è¯„è®º"""
        t = str(int(time.time() * 1000))
        
        data_params = {
            "showTrueCount": ${config.apiParams.showTrueCount ? 'True' : 'False'},
            "auctionNumId": "${config.apiParams.auctionNumId}",
            "pageNo": page_no,
            "pageSize": page_size,
            "orderType": "${config.apiParams.orderType}",
            "searchImpr": "${config.apiParams.searchImpr}",
            "expression": "${config.apiParams.expression}",
            "skuVids": "${config.apiParams.skuVids}",
            "rateSrc": "${config.apiParams.rateSrc}",
            "rateType": "${config.apiParams.rateType}"
        }
        
        data_str = json.dumps(data_params, separators=(',', ':'))
        
        token = self._extract_token(self.cookies_str) if self.cookies_str else ""
        signature = self._generate_signature(t, data_str, token)
        
        url_params = {
            'jsv': '2.7.4',
            'appKey': '12574478',
            't': t,
            'sign': signature,
            'api': 'mtop.taobao.rate.detaillist.get',
            'v': '6.0',
            'isSec': '0',
            'ecode': '1',
            'timeout': '20000',
            'dataType': 'jsonp',
            'valueType': 'string',
            'type': 'jsonp',
            'callback': 'mtopjsonp12',
            'data': data_str
        }
        
        url = f"{self.base_url}?{urllib.parse.urlencode(url_params)}"
        
        try:
            response = self.session.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            json_data = self._parse_jsonp_response(response.text)
            
            if json_data:
                return {
                    'success': True,
                    'comments': self._format_comments(json_data),
                    'total': json_data.get('data', {}).get('total', 0)
                }
            else:
                return {'success': False, 'error': 'å“åº”è§£æå¤±è´¥'}
                
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def get_multiple_pages(self, max_pages=${config.maxPages}, page_size=${config.pageSize}, delay=2):
        """è·å–å¤šé¡µè¯„è®º"""
        all_comments = []
        
        for page in range(1, max_pages + 1):
            print(f"æ­£åœ¨è·å–ç¬¬ {page} é¡µè¯„è®º...")
            
            result = self.get_comments(page_no=page, page_size=page_size)
            
            if result['success']:
                comments = result['comments']
                if comments:
                    all_comments.extend(comments)
                    print(f"ç¬¬ {page} é¡µè·å–åˆ° {len(comments)} æ¡è¯„è®º")
                else:
                    print(f"ç¬¬ {page} é¡µæ²¡æœ‰æ›´å¤šè¯„è®º")
                    break
            else:
                print(f"ç¬¬ {page} é¡µè·å–å¤±è´¥: {result['error']}")
                break
            
            if page < max_pages:
                time.sleep(delay)
        
        return all_comments
    
    def save_to_file(self, comments, filename):
        """ä¿å­˜è¯„è®ºåˆ°æ–‡ä»¶"""
        try:
            os.makedirs('output', exist_ok=True)
            filepath = f"output/{filename}"
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(comments, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
            return filepath
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return None


def main():
    """ä¸»ç¨‹åº"""
    print("ğŸ›’ æ·˜å®/å¤©çŒ«å•†å“è¯„è®ºçˆ¬è™« (è‡ªåŠ¨é…ç½®ç‰ˆ)")
    print("=" * 50)
    
    spider = TmallCommentSpider()
    
    print(f"ğŸ¯ å•†å“ID: {spider.product_id}")
    print(f"ğŸ“¡ å¼€å§‹è·å–è¯„è®ºæ•°æ®...")
    
    comments = spider.get_multiple_pages()
    
    if comments:
        print(f"\\nğŸ‰ æˆåŠŸè·å– {len(comments)} æ¡è¯„è®º")
        
        filename = f"comments_{spider.product_id}_{int(time.time())}.json"
        spider.save_to_file(comments, filename)
        
        print(f"\\nğŸ“ è¯„è®ºé¢„è§ˆ:")
        for i, comment in enumerate(comments[:3], 1):
            print(f"\\nğŸ”¸ è¯„è®º {i}:")
            print(f"   ç”¨æˆ·: {comment['user_nick']}")
            print(f"   è¯„åˆ†: {'â˜…' * comment['rating']}")
            print(f"   å†…å®¹: {comment['content'][:50]}...")
            print(f"   æ—¶é—´: {comment['date']}")
            if comment['useful_count'] > 0:
                print(f"   ç‚¹èµ: {comment['useful_count']}")
        
        print(f"\\nâœ… çˆ¬å–å®Œæˆï¼æ•°æ®å·²ä¿å­˜ã€‚")
    else:
        print("âŒ æœªè·å–åˆ°ä»»ä½•è¯„è®ºæ•°æ®")


if __name__ == "__main__":
    main()
`;
}

async function updateOriginalSpider(spiderPath: string, config: SpiderConfig): Promise<string> {
  try {
    const originalCode = await fs.readFile(spiderPath, 'utf-8');
    
    // æ›´æ–°å•†å“ID
    let updatedCode = originalCode.replace(
      /product_id = os\.getenv\('PRODUCT_ID', '[^']*'\)/,
      `product_id = os.getenv('PRODUCT_ID', '${config.productId}')`
    );
    
    // æ›´æ–°cookies
    const cookiesRegex = /cookies = """[\s\S]*?"""/;
    const newCookiesStr = `cookies = """${config.cookies}"""`;
    updatedCode = updatedCode.replace(cookiesRegex, newCookiesStr);
    
    return updatedCode;
  } catch (error) {
    console.error('æ›´æ–°åŸå§‹çˆ¬è™«æ–‡ä»¶å¤±è´¥:', error);
    throw error;
  }
}
