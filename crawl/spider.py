#!/usr/bin/env python3
"""
æ·˜å®/å¤©çŒ«å•†å“è¯„è®ºçˆ¬è™« - ä¸»ç¨‹åº
ä½¿ç”¨æ–¹æ³•: python3 spider.py
"""

import requests
import time
import json
import urllib.parse
import re
import hashlib
import os
from fake_useragent import UserAgent
from database_reader import DatabaseReader


class TmallCommentSpider:
    """å¤©çŒ«å•†å“è¯„è®ºçˆ¬è™«"""
    
    def __init__(self, cookies=None):
        self.session = requests.Session()
        self.ua = UserAgent()
        self.base_url = "https://h5api.m.tmall.com/h5/mtop.taobao.rate.detaillist.get/6.0/"
        self.cookies_str = cookies
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.headers = {
            'accept': '*/*',
            'accept-encoding': 'gzip, deflate, br',
            'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'cache-control': 'no-cache',
            'pragma': 'no-cache',
            'referer': 'https://detail.tmall.com/',
            'sec-ch-ua': '"Not;A=Brand";v="99", "Google Chrome";v="139", "Chromium";v="139"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"macOS"',
            'sec-fetch-dest': 'script',
            'sec-fetch-mode': 'no-cors',
            'sec-fetch-site': 'same-site',
            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',
            'origin': 'https://detail.tmall.com',
            'x-requested-with': 'XMLHttpRequest'
        }
        
        # è®¾ç½®cookies
        if cookies:
            self.session.cookies.update(self._parse_cookies(cookies))
    
    def _parse_cookies(self, cookie_string):
        """è§£æcookieå­—ç¬¦ä¸²ä¸ºå­—å…¸"""
        cookies = {}
        if cookie_string:
            for item in cookie_string.split('; '):
                if '=' in item:
                    key, value = item.split('=', 1)
                    cookies[key] = value
        return cookies
    
    def _extract_token(self, cookies_str):
        """ä»cookiesä¸­æå–_m_h5_tk token"""
        match = re.search(r'_m_h5_tk=([^;]+)', cookies_str)
        if match:
            token_with_timestamp = match.group(1)
            token = token_with_timestamp.split('_')[0] if '_' in token_with_timestamp else token_with_timestamp
            return token
        return ""
    
    def _generate_signature(self, timestamp, data_str, token=""):
        """ç”Ÿæˆç­¾å"""
        app_key = "12574478"
        if not token:
            sign_str = f"{timestamp}&{app_key}&{data_str}"
        else:
            sign_str = f"{token}&{timestamp}&{app_key}&{data_str}"
        return hashlib.md5(sign_str.encode('utf-8')).hexdigest()
    
    def _parse_jsonp_response(self, response_text):
        """è§£æJSONPå“åº”"""
        match = re.search(r'mtopjsonp\d+\((.*)\)', response_text)
        if match:
            json_str = match.group(1)
            try:
                return json.loads(json_str)
            except json.JSONDecodeError as e:
                print(f"JSONè§£æé”™è¯¯: {e}")
                return None
        return None
    
    def _format_comments(self, raw_data):
        """æ ¼å¼åŒ–è¯„è®ºæ•°æ®"""
        if not raw_data or 'data' not in raw_data:
            return []
        
        comments = []
        try:
            # è·å–è¯„è®ºåˆ—è¡¨
            rate_list = raw_data['data'].get('rateList', [])
            
            for rate in rate_list:
                comment = {
                    'user_nick': rate.get('userNick', rate.get('reduceUserNick', '')),
                    'content': rate.get('feedback', ''),
                    'rating': int(rate.get('userStar', 0)),
                    'date': rate.get('feedbackDate', rate.get('createTime', '')),
                    'useful_count': 0,
                    'reply': rate.get('reply', ''),
                    'sku_info': rate.get('skuValueStr', ''),
                    'pics': []
                }
                
                # æå–ç‚¹èµæ•°
                if 'interactInfo' in rate and isinstance(rate['interactInfo'], dict):
                    comment['useful_count'] = int(rate['interactInfo'].get('likeCount', 0))
                
                # æå–å›¾ç‰‡
                if 'feedPicPathList' in rate and isinstance(rate['feedPicPathList'], list):
                    comment['pics'] = rate['feedPicPathList']
                
                comments.append(comment)
                
        except Exception as e:
            print(f"æ•°æ®æ ¼å¼åŒ–é”™è¯¯: {e}")
        
        return comments
    
    def get_product_info_from_comments(self, comments):
        """ä»è¯„è®ºæ•°æ®ä¸­æ¨æ–­å•†å“ä¿¡æ¯"""
        if not comments or len(comments) == 0:
            return {
                'success': True,
                'product_name': 'æœªçŸ¥å•†å“',
                'product_url': '',
                'shop_name': ''
            }
        
        # ä»è¯„è®ºçš„SKUä¿¡æ¯æ¨æ–­å•†å“ç±»å‹
        sku_keywords = []
        for comment in comments[:3]:  # åªæ£€æŸ¥å‰3æ¡è¯„è®º
            sku_info = comment.get('sku_info', '')
            if sku_info:
                sku_keywords.append(sku_info)
        
        # æ ¹æ®SKUå…³é”®è¯æ¨æ–­å•†å“ç±»å‹
        product_name = 'å•†å“'
        if any('æ‰“ç«æœº' in sku or 'ç«çŸ³' in sku for sku in sku_keywords):
            product_name = 'æ‰“ç«æœºå•†å“'
        elif any('ç¤¼ç›’' in sku for sku in sku_keywords):
            product_name = 'ç¤¼ç›’å•†å“'
        elif any('ç¬”è®°æœ¬' in sku or 'æœ¬å­' in sku for sku in sku_keywords):
            product_name = 'ç¬”è®°æœ¬å•†å“'
        elif any('æ‰‹æœº' in sku for sku in sku_keywords):
            product_name = 'æ‰‹æœºå•†å“'
        elif any('è¡£æœ' in sku or 'æœè£…' in sku for sku in sku_keywords):
            product_name = 'æœè£…å•†å“'
        elif any('é‹å­' in sku or 'é‹' in sku for sku in sku_keywords):
            product_name = 'é‹ç±»å•†å“'
        elif any('åŒ…' in sku for sku in sku_keywords):
            product_name = 'åŒ…ç±»å•†å“'
        
        return {
            'success': True,
            'product_name': product_name,
            'product_url': '',
            'shop_name': ''
        }

    def get_product_info(self, product_id):
        """è·å–å•†å“åŸºæœ¬ä¿¡æ¯"""
        try:
            # å…ˆå°è¯•è·å–è¯„è®ºæ•°æ®
            result = self.get_comments(product_id, page_no=1, page_size=3)
            
            if result['success'] and 'comments' in result:
                # ä»è¯„è®ºæ•°æ®ä¸­æ¨æ–­å•†å“ä¿¡æ¯
                return self.get_product_info_from_comments(result['comments'])
            elif result['success'] and 'data' in result:
                data = result['data']
                print(f"è°ƒè¯• - è¯„è®ºæ•°æ®å­—æ®µ: {list(data.keys())}")
                
                # å°è¯•ä»ä¸åŒå­—æ®µè·å–å•†å“ä¿¡æ¯
                product_name = f'å•†å“ID: {product_id}'
                product_url = ''
                shop_name = ''
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å•†å“ç›¸å…³å­—æ®µ
                if 'item' in data:
                    item = data['item']
                    product_name = item.get('title', product_name)
                    product_url = item.get('url', product_url)
                    shop_name = item.get('shopName', shop_name)
                elif 'auction' in data:
                    auction = data['auction']
                    product_name = auction.get('title', product_name)
                    product_url = auction.get('url', product_url)
                    shop_name = auction.get('shopName', shop_name)
                elif 'product' in data:
                    product = data['product']
                    product_name = product.get('title', product_name)
                    product_url = product.get('url', product_url)
                    shop_name = product.get('shopName', shop_name)
                
                # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°å•†å“åç§°ï¼Œå°è¯•ä»è¯„è®ºçš„SKUä¿¡æ¯æ¨æ–­
                if product_name == f'å•†å“ID: {product_id}' and 'rateList' in data:
                    rate_list = data['rateList']
                    if rate_list and len(rate_list) > 0:
                        # ä»ç¬¬ä¸€ä¸ªè¯„è®ºçš„SKUä¿¡æ¯æ¨æ–­å•†å“ç±»å‹
                        first_comment = rate_list[0]
                        sku_info = first_comment.get('skuValueStr', '')
                        if sku_info:
                            # æ ¹æ®SKUä¿¡æ¯æ¨æ–­å•†å“ç±»å‹
                            if 'æ‰“ç«æœº' in sku_info or 'ç«çŸ³' in sku_info:
                                product_name = f'æ‰“ç«æœºå•†å“ - {product_id}'
                            elif 'ç¤¼ç›’' in sku_info:
                                product_name = f'ç¤¼ç›’å•†å“ - {product_id}'
                            else:
                                product_name = f'å•†å“ - {product_id}'
                
                return {
                    'success': True,
                    'product_name': product_name,
                    'product_url': product_url,
                    'shop_name': shop_name
                }
            
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›é»˜è®¤å€¼
            return {
                'success': True,
                'product_name': f'å•†å“ID: {product_id}',
                'product_url': '',
                'shop_name': ''
            }
        except Exception as e:
            print(f"è·å–å•†å“ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'success': False,
                'product_name': f'å•†å“ID: {product_id}',
                'product_url': '',
                'shop_name': ''
            }

    def get_comments(self, product_id, page_no=1, page_size=20):
        """è·å–å•†å“è¯„è®º"""
        # æ„å»ºè¯·æ±‚å‚æ•°
        t = str(int(time.time() * 1000))
        
        data_params = {
            "showTrueCount": False,
            "auctionNumId": product_id,
            "pageNo": page_no,
            "pageSize": page_size,
            "orderType": "",
            "searchImpr": "-8",
            "expression": "",
            "skuVids": "",
            "rateSrc": "pc_rate_list",
            "rateType": ""
        }
        
        data_str = json.dumps(data_params, separators=(',', ':'))
        
        # ç”Ÿæˆç­¾å
        token = self._extract_token(self.cookies_str) if self.cookies_str else ""
        signature = self._generate_signature(t, data_str, token)
        
        # URLå‚æ•°
        url_params = {
            'jsv': '2.7.4',
            'appKey': '12574478',
            't': t,
            'sign': signature,
            'api': 'mtop.taobao.rate.detaillist.get',
            'v': '6.0',
            'isSec': '0',
            'ecode': '1',
            'timeout': '20000',
            'dataType': 'jsonp',
            'valueType': 'string',
            'type': 'jsonp',
            'callback': 'mtopjsonp12',
            'data': data_str
        }
        
        url = f"{self.base_url}?{urllib.parse.urlencode(url_params)}"
        
        try:
            response = self.session.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            json_data = self._parse_jsonp_response(response.text)
            
            if json_data:
                return {
                    'success': True,
                    'comments': self._format_comments(json_data),
                    'total': json_data.get('data', {}).get('total', 0)
                }
            else:
                return {'success': False, 'error': 'å“åº”è§£æå¤±è´¥'}
                
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def get_multiple_pages(self, product_id, max_pages=3, page_size=20, delay=2):
        """è·å–å¤šé¡µè¯„è®º"""
        all_comments = []
        
        for page in range(1, max_pages + 1):
            print(f"æ­£åœ¨è·å–ç¬¬ {page} é¡µè¯„è®º...")
            
            result = self.get_comments(product_id, page_no=page, page_size=page_size)
            
            if result['success']:
                comments = result['comments']
                if comments:
                    all_comments.extend(comments)
                    print(f"ç¬¬ {page} é¡µè·å–åˆ° {len(comments)} æ¡è¯„è®º")
                else:
                    print(f"ç¬¬ {page} é¡µæ²¡æœ‰æ›´å¤šè¯„è®º")
                    break
            else:
                print(f"ç¬¬ {page} é¡µè·å–å¤±è´¥: {result['error']}")
                break
            
            if page < max_pages:
                time.sleep(delay)
        
        return all_comments
    


def main():
    """ä¸»ç¨‹åº"""
    print("ğŸ›’ æ·˜å®/å¤©çŒ«å•†å“è¯„è®ºçˆ¬è™«")
    print("=" * 50)
    
    # ä»ç¯å¢ƒå˜é‡è·å–å‚æ•°
    product_id = os.getenv('PRODUCT_ID', '933910033859')
    max_pages = int(os.getenv('MAX_PAGES', '3'))
    use_database = os.getenv('USE_DATABASE', 'true').lower() == 'true'
    
    print(f"ğŸ¯ å•†å“ID: {product_id}")
    print(f"ğŸ“„ æœ€å¤§é¡µæ•°: {max_pages}")
    print(f"ğŸ—„ï¸ ä½¿ç”¨æ•°æ®åº“: {use_database}")
    
    # åˆå§‹åŒ–æ•°æ®åº“è¯»å–å™¨
    db_reader = None
    if use_database:
        try:
            db_reader = DatabaseReader()
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            print("âš ï¸ å°†ä½¿ç”¨ç¯å¢ƒå˜é‡å‚æ•°")
            use_database = False
    
    # è·å–é…ç½®å‚æ•°
    cookies = ""
    actual_max_pages = max_pages
    product_name = f"å•†å“ID: {product_id}"
    
    if use_database and db_reader:
        # ä»æ•°æ®åº“è·å–é…ç½®
        print("ğŸ” æ­£åœ¨ä»æ•°æ®åº“è·å–é…ç½®...")
        config = db_reader.get_spider_config_by_product_id(product_id)
        
        if config:
            cookies = config.get('cookies', '')
            actual_max_pages = config.get('max_pages', max_pages)
            product_name = config.get('product_name', product_name)
            print(f"âœ… ä»æ•°æ®åº“è·å–é…ç½®æˆåŠŸ:")
            print(f"   - cookiesé•¿åº¦: {len(cookies)}")
            print(f"   - maxPages: {actual_max_pages}")
            print(f"   - å•†å“åç§°: {product_name}")
        else:
            print("âŒ æ•°æ®åº“ä¸­æœªæ‰¾åˆ°è¯¥å•†å“çš„é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
            cookies = os.getenv('COOKIES', '')
    else:
        # ä½¿ç”¨ç¯å¢ƒå˜é‡å‚æ•°
        cookies = os.getenv('COOKIES', '')
        print("âš ï¸ ä½¿ç”¨ç¯å¢ƒå˜é‡å‚æ•°")
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    spider = TmallCommentSpider(cookies=cookies)
    
    print(f"ğŸ“¡ å¼€å§‹è·å–å•†å“ä¿¡æ¯...")
    
    # è·å–å•†å“ä¿¡æ¯
    product_info = spider.get_product_info(product_id)
    if product_info.get('success'):
        product_name = product_info.get('product_name', product_name)
    print(f"ğŸ“¦ å•†å“ä¿¡æ¯: {product_info}")
    
    print(f"ğŸ“¡ å¼€å§‹è·å–è¯„è®ºæ•°æ®...")
    
    # æµ‹è¯•å•é¡µè·å–
    print(f"ğŸ” æµ‹è¯•è·å–ç¬¬1é¡µæ•°æ®...")
    test_result = spider.get_comments(product_id, page_no=1, page_size=20)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {test_result}")
    
    # è·å–è¯„è®ºæ•°æ®
    comments = spider.get_multiple_pages(product_id, max_pages=actual_max_pages, page_size=20)
    
    if comments:
        print(f"\nğŸ‰ æˆåŠŸè·å– {len(comments)} æ¡è¯„è®º")
        
        # æ˜¾ç¤ºå‰3æ¡è¯„è®º
        print(f"\nğŸ“ è¯„è®ºé¢„è§ˆ:")
        for i, comment in enumerate(comments[:3], 1):
            print(f"\nğŸ”¸ è¯„è®º {i}:")
            print(f"   ç”¨æˆ·: {comment['user_nick']}")
            print(f"   è¯„åˆ†: {'â˜…' * comment['rating']}")
            print(f"   å†…å®¹: {comment['content'][:50]}...")
            print(f"   æ—¶é—´: {comment['date']}")
            if comment['useful_count'] > 0:
                print(f"   ç‚¹èµ: {comment['useful_count']}")
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        if use_database and db_reader:
            print("ğŸ’¾ æ­£åœ¨ä¿å­˜è¯„è®ºæ•°æ®åˆ°æ•°æ®åº“...")
            save_success = db_reader.save_comments(product_id, comments)
            if save_success:
                print("âœ… è¯„è®ºæ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“")
            else:
                print("âŒ ä¿å­˜è¯„è®ºæ•°æ®å¤±è´¥")
        
        print(f"\nâœ… çˆ¬å–å®Œæˆï¼")
        
        # è¾“å‡ºJSONæ ¼å¼çš„æ•°æ®ä¾›Node.jsä½¿ç”¨
        output_data = {
            "success": True,
            "comments": comments,
            "total": len(comments),
            "product_info": {
                "success": True,
                "product_name": product_name,
                "product_url": "",
                "shop_name": ""
            }
        }
        print(f"\nğŸ“Š JSON_DATA_START")
        print(json.dumps(output_data, ensure_ascii=False, indent=2))
        print(f"ğŸ“Š JSON_DATA_END")
    else:
        print("âŒ æœªè·å–åˆ°ä»»ä½•è¯„è®ºæ•°æ®")
        # è¾“å‡ºç©ºçš„JSONæ•°æ®
        output_data = {
            "success": False,
            "comments": [],
            "total": 0,
            "product_info": {
                "success": True, 
                "product_name": product_name, 
                "product_url": "", 
                "shop_name": ""
            }
        }
        print(f"\nğŸ“Š JSON_DATA_START")
        print(json.dumps(output_data, ensure_ascii=False, indent=2))
        print(f"ğŸ“Š JSON_DATA_END")


if __name__ == "__main__":
    main()
